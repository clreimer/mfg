{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n",
    "\n",
    "## Import Datalogue libraries\n",
    "\n",
    "Note, you'll need to have downloaded and installed the Datalogue SDK before this step will work.\n",
    "\n",
    "Right now, to do so you will need to get access through Artifactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.31.1'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Datalogue libraries \n",
    "from datalogue import *\n",
    "from datalogue.version import __version__\n",
    "from datalogue.models.ontology import *\n",
    "from datalogue.models.datastore_collection import *\n",
    "from datalogue.models.datastore import *\n",
    "from datalogue.models.datastore import GCSDatastoreDef \n",
    "from datalogue.models.credentials import *\n",
    "from datalogue.models.stream import *\n",
    "from datalogue.models.transformations import *\n",
    "from datalogue.models.transformations.structure import *\n",
    "from datalogue.dtl import Dtl, DtlCredentials\n",
    "from datalogue.models.training import DataRef\n",
    "\n",
    "# Import Datalogue Bag of Tricks\n",
    "from DTLBagOTricks import DTL as DTLHelper\n",
    "\n",
    "\n",
    "# Import other useful libraries\n",
    "from datetime import datetime, timedelta\n",
    "from os import environ\n",
    "import pandas\n",
    "from IPython.display import Image\n",
    "\n",
    "# Checks the version of the SDK is correct\n",
    "# The expected version is 0.28.3\n",
    "# If the SDK is not installed, run `! pip install datalogue` and restart the Jupyter Notebook kernel\n",
    "# If the wrong versions is installed, run `! pip install datalogue --upgrade` and restart the Jupyter Notebook kernel\n",
    "__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datalogue v0.31.1\n",
      "Logged in 'https://internal.dtl.systems/api' with 'chrisr@datalogue.io' account.\n"
     ]
    }
   ],
   "source": [
    "# Set host, username and password variables\n",
    "\n",
    "datalogue_host = \"https://internal.dtl.systems\"  # for connecting to internal (note)\n",
    "\n",
    "# datalogue_host = \"https://internal.dtl.systems\"  # for connecting to internal (note)\n",
    "# datalogue_host = \"http://10.2.161.119:3000\"  # for connecting to Eric's DGX\n",
    "#email = environ.get(\"DTL_EMAIL\")\n",
    "email = \"chrisr@datalogue.io\"\n",
    "#password = environ.get(\"DTL_PASSWORD\")\n",
    "password = \"StreudelSauce1!\"\n",
    "\n",
    "# Log in to Datalogue\n",
    "BOT = DTLHelper(datalogue_host, email, password)\n",
    "dtl = BOT.dtl\n",
    "\n",
    "# Expected output Datalogue v0.28.3\n",
    "# \"Logged in '[host location]' with '[username]' account)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b00f972c-8c68-49c1-8de5-babde571ae92\n",
      "b05710cc-62cb-4e59-b337-6fc49fd88433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploy the model before the tidy up to give it some time to be ready:\n",
    "\n",
    "from datalogue.models.training import *\n",
    "import uuid\n",
    "\n",
    "OntologyId = 'b00f972c-8c68-49c1-8de5-babde571ae92'\n",
    "trainingId = dtl.training.get_trainings(uuid.UUID(str(OntologyId)))[0].id\n",
    "\n",
    "print(OntologyId)\n",
    "print(trainingId)\n",
    "\n",
    "dtl.training.deploy(trainingId, OntologyId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's clean up the assets this workbook creates from previous runs\n",
    "\n",
    "# Warning! this will clean all your datastores and data collections and credentials\n",
    "\n",
    "#BOT.server_summary()\n",
    "\n",
    "# Clear Datastores and Datastore Collections\n",
    "for store in dtl.datastore.list():\n",
    "#    print(store.name, ',', store.name[:5])\n",
    "    if (store.name == 'dtl-demo mfg'):\n",
    "        targetDS = store.id\n",
    "        \n",
    "    if (store.name[:5] == 'demo-'):\n",
    "        dtl.datastore.delete(store.id)\n",
    "\n",
    "for store in dtl.datastore_collection.list():\n",
    "#    print(store.name)\n",
    "    if (store.name[:5] == 'demo-'):    \n",
    "        dtl.datastore_collection.delete(store.id)\n",
    "\n",
    "# Clear data pipelines\n",
    "for StreamCollection in dtl.stream_collection.list():\n",
    "#    print(StreamCollection, '\\n')\n",
    "    if (StreamCollection.name[:5] == 'demo-'):\n",
    "        dtl.stream_collection.delete(StreamCollection.id)\n",
    "\n",
    "## Clear ontologies\n",
    "for Ontology in dtl.ontology.list():\n",
    "#     dtl.ontology.delete(ontology.id)\n",
    "    if (Ontology.name[:12] == 'MFG Ontology'):\n",
    "        OntologyID = Ontology.id\n",
    "\n",
    "#BOT.server_summary()\n",
    "\n",
    "# After running the above, the Stores and Collections variables should both be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "PostgreSQL database version:\n",
      "('PostgreSQL 11.5 on x86_64-pc-linux-gnu, compiled by gcc (Debian 7.3.0-5) 7.3.0, 64-bit',)\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# truncate the postgres table before writing data\n",
    "\n",
    "import psycopg2\n",
    "#from config import Config\n",
    " \n",
    "def connect():\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # read connection parameters\n",
    "        #params = config()\n",
    " \n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        #conn = psycopg2.connect(**params)\n",
    "        conn = psycopg2.connect(host=\"34.73.161.131\",database=\"demo\", user=\"postgres\", password=\"devout-north-solitude\")\n",
    "\n",
    "      \n",
    "        # create a cursor\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "   # execute a statement\n",
    "        print('PostgreSQL database version:')\n",
    "        cur.execute('SELECT version()')\n",
    " \n",
    "        # display the PostgreSQL database server version\n",
    "        db_version = cur.fetchone()\n",
    "        print(db_version)\n",
    "        \n",
    "        # truncate the table\n",
    "        cur.execute('TRUNCATE TABLE mfg')\n",
    "        \n",
    "       # close the communication with the PostgreSQL\n",
    "        cur.close()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            print('Database connection closed.')\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read Source Files from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "[{'store_name': 'demo-mfg/00_data_machine.csv', 'URL': 'https://datalogue-demo.s3.amazonaws.com/mfg/00_data_machine.csv'}, {'store_name': 'demo-mfg/01_data_machine.csv', 'URL': 'https://datalogue-demo.s3.amazonaws.com/mfg/01_data_machine.csv'}, {'store_name': 'demo-mfg/02_data_machine.csv', 'URL': 'https://datalogue-demo.s3.amazonaws.com/mfg/02_data_machine.csv'}, {'store_name': 'demo-mfg/03-data_machine.json', 'URL': 'https://datalogue-demo.s3.amazonaws.com/mfg/03-data_machine.json'}, {'store_name': 'demo-mfg/04-data_machine.json', 'URL': 'https://datalogue-demo.s3.amazonaws.com/mfg/04-data_machine.json'}]\n"
     ]
    }
   ],
   "source": [
    "from boto.s3.connection import S3Connection\n",
    "\n",
    "conn = S3Connection('AKIAIXM6CXHGHC62R7GA','Gcb34qctsvPoQJGGDrXzmwMbyaCZOg6zY1RFOVQO')\n",
    "bucket = conn.get_bucket('datalogue-demo')\n",
    "\n",
    "keys = [\"store_name\", \"URL\"]\n",
    "npl_data = []\n",
    "\n",
    "for key in bucket.list():\n",
    "    if 'data_machine' in key.name:\n",
    "        url=\"https://datalogue-demo.s3.amazonaws.com/\" + key.name\n",
    "        values = [\"demo-\"+key.name, url]\n",
    "        npl_data.append(dict(zip(keys, values)))\n",
    "            \n",
    "print(type(npl_data))\n",
    "print(type(npl_data[0]))\n",
    "print(npl_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV Machine Sources to connect to:\n",
      "-------------------------\n",
      "➜ demo-mfg/00_data_machine.csv\n",
      "➜ demo-mfg/01_data_machine.csv\n",
      "➜ demo-mfg/02_data_machine.csv\n",
      "➜ demo-mfg/03-data_machine.json\n",
      "➜ demo-mfg/04-data_machine.json\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nCSV Machine Sources to connect to:\\n\" \"-------------------------\")\n",
    "for data_store in npl_data:\n",
    "    print(\"➜ \" + data_store[\"store_name\"])\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create datastore connections for each file in S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'datalogue.models.datastore.Datastore'>\n",
      "{'store_name': 'demo-mfg/04-data_machine.json', 'URL': 'https://datalogue-demo.s3.amazonaws.com/mfg/04-data_machine.json', 'datastore_object': Datastore(id: 72f11ac2-fb2e-4ab7-9a12-2fc9fc204193, name: 'demo-mfg/04-data_machine.json', alias: None, credential_id: None, definition: <datalogue.models.datastore.HttpDatastoreDef object at 0x000002C5C5CBB898>, samples: None, schema_paths: [], schema_labels: [], schema_nodes: None)}\n"
     ]
    }
   ],
   "source": [
    "current_stores = []\n",
    "\n",
    "for data_store in npl_data:\n",
    "#    print(data_store[\"store_name\"], \"---\", data_store[\"store_name\"][-4:])\n",
    "    if (data_store[\"store_name\"][-4:] == '.csv'):\n",
    "        data_store[\"datastore_object\"] = dtl.datastore.create(\n",
    "            Datastore(\n",
    "                data_store[\"store_name\"],\n",
    "                HttpDatastoreDef(data_store[\"URL\"], FileFormat.Csv),))\n",
    "    if (data_store[\"store_name\"][-4:] == '.xml'):\n",
    "        data_store[\"datastore_object\"] = dtl.datastore.create(\n",
    "            Datastore(\n",
    "                data_store[\"store_name\"],\n",
    "                HttpDatastoreDef(data_store[\"URL\"], FileFormat.Xml),))\n",
    "    if (data_store[\"store_name\"][-4:] == 'json'):\n",
    "        data_store[\"datastore_object\"] = dtl.datastore.create(\n",
    "            Datastore(\n",
    "                data_store[\"store_name\"],\n",
    "                HttpDatastoreDef(data_store[\"URL\"], FileFormat.Json),))\n",
    "\n",
    "    current_stores.append(data_store[\"datastore_object\"])\n",
    "\n",
    "print(type(current_stores))\n",
    "print(type(current_stores[0]))\n",
    "\n",
    "print(data_store)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###           3b. Create datastore for RDBMS target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host: 34.74.11.127 (use jdbc:postgresql://34.74.11.127:5432/demo for creating target store)\n",
    "# user: postgres\n",
    "# pw: L8am0pO5zjJrFm2O\n",
    "\n",
    "# bug in SDK for v<1.0; to be updated here but created in GUI for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collecting data stores into a collection\n",
    "\n",
    "This is just used for organization, and uses the command `dtl.datastore_collection.create`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatastoreCollection(id: e16e9369-7164-427c-8f9e-677b74b2d6af, name: 'demo-MFG Collection')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npl_collection = DatastoreCollection(\n",
    "  name =\"demo-MFG Collection\",\n",
    "  storeIds = [Datastore[\"datastore_object\"].id for Datastore in npl_data],\n",
    "  description = \"Manufacturing data of various formats\"\n",
    ")\n",
    "\n",
    "dtl.datastore_collection.create(npl_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b00f972c-8c68-49c1-8de5-babde571ae92\n",
      "b05710cc-62cb-4e59-b337-6fc49fd88433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deploy the model\n",
    "from datalogue.models.training import *\n",
    "import uuid\n",
    "\n",
    "OntologyId = 'b00f972c-8c68-49c1-8de5-babde571ae92'\n",
    "trainingId = dtl.training.get_trainings(uuid.UUID(str(OntologyID)))[0].id\n",
    "\n",
    "print(OntologyId)\n",
    "print(trainingId)\n",
    "\n",
    "dtl.training.deploy(trainingId, OntologyId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating a stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datastore(id: 5d4f4f1b-55d6-4ef0-823e-d37d7f58dc3f, name: 'dtl-demo mfg', alias: None, credential_id: 970d851a-e74d-4edf-b604-af18ffdaf009, definition: <datalogue.models.datastore.JdbcDatastoreDef object at 0x000002C5C444EA58>, samples: None, schema_paths: [], schema_labels: [], schema_nodes: None)\n"
     ]
    }
   ],
   "source": [
    "#set target of stream:\n",
    "my_output_store = dtl.datastore.get(targetDS)\n",
    "print(my_output_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target output schema transformation using 'structure'\n",
    "\n",
    "std_schema = Structure([\n",
    "        ClassNodeDescription(\n",
    "            path = [\"Machine ID_\"],\n",
    "            tag = \"Machine ID\",\n",
    "            pick_strategy = PickStrategy.HighScore,\n",
    "            data_type = DataType.String\n",
    "        ),\n",
    "        ClassNodeDescription(\n",
    "            path = [\"Part ID_\"],\n",
    "            tag = \"Part ID\",\n",
    "            pick_strategy = PickStrategy.HighScore,\n",
    "            data_type = DataType.String\n",
    "        ),\n",
    "        ClassNodeDescription(\n",
    "            path = [\"Output Qty_\"],\n",
    "            tag = \"Output Qty\",\n",
    "            pick_strategy = PickStrategy.HighScore,\n",
    "            data_type = DataType.String\n",
    "        ),\n",
    "        ClassNodeDescription(\n",
    "            path = [\"Timestamp_\"],\n",
    "            tag = \"Timestamp\",\n",
    "            pick_strategy = PickStrategy.HighScore,\n",
    "            data_type = DataType.String\n",
    "        ),\n",
    "        ClassNodeDescription(\n",
    "            path = [\"Machine Status_\"],\n",
    "            tag = \"Machine Status\",\n",
    "            pick_strategy = PickStrategy.HighScore,\n",
    "            data_type = DataType.String\n",
    "        ),\n",
    "        ClassNodeDescription(\n",
    "            path = [\"Rejects_\"],\n",
    "            tag = \"Rejects\",\n",
    "            pick_strategy = PickStrategy.HighScore,\n",
    "            data_type = DataType.String\n",
    "        ),\n",
    "        ClassNodeDescription(\n",
    "            path = [\"City_\"],\n",
    "            tag = \"City\",\n",
    "            pick_strategy = PickStrategy.HighScore,\n",
    "            data_type = DataType.String\n",
    "        ),\n",
    "        ClassNodeDescription(\n",
    "            path = [\"Line ID_\"],\n",
    "            tag = \"Line ID\",\n",
    "            pick_strategy = PickStrategy.HighScore,\n",
    "            data_type = DataType.String\n",
    "        ),\n",
    "        ClassNodeDescription(\n",
    "            path = [\"State_\"],\n",
    "            tag = \"State\",\n",
    "            pick_strategy = PickStrategy.HighScore,\n",
    "            data_type = DataType.String\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b05710cc-62cb-4e59-b337-6fc49fd88433\n"
     ]
    }
   ],
   "source": [
    "from datalogue.models.training import *\n",
    "import uuid\n",
    "\n",
    "modelUuid = dtl.training.get_trainings(uuid.UUID(str(OntologyID)))[0].id\n",
    "print(modelUuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classify transformation\n",
    "\n",
    "#tx_definition = Definition(    # (List[Transformation], pipelines: List['Definition'], target_datastore )\n",
    "#            [\n",
    "#                Classify(training_id = modelUuid, use_context=True, include_classes=False, include_scores=False),\n",
    "#                std_schema\n",
    "#            ], # List of transformations\n",
    "#        [], # pipelines list\n",
    "#            my_output_store, # target_datastore\n",
    "#        )\n",
    "\n",
    "#print(type(tx_definition))\n",
    "#print(tx_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "b05710cc-62cb-4e59-b337-6fc49fd88433\n"
     ]
    }
   ],
   "source": [
    "x = dtl.training.get_trainings('b00f972c-8c68-49c1-8de5-babde571ae92')\n",
    "print(type(x))\n",
    "print(x[0].id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datalogue.models.stream.Definition'>\n",
      "Pipeline(type: [Classify(classifier: Classifier(default_class: None classification_methods: \n",
      "[MLMethod(\n",
      " model_id: b05710cc-62cb-4e59-b337-6fc49fd88433, threshold: None\n",
      ")]), fields_to_target: None, add_class_fields: False, add_score_fields: False), Structure(structure: [ClassNodeDescription(path: ['Machine ID_'], tag: Machine ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Part ID_'], tag: Part ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Output Qty_'], tag: Output Qty, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Timestamp_'], tag: Timestamp, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Machine Status_'], tag: Machine Status, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Rejects_'], tag: Rejects, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['City_'], tag: City, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Line ID_'], tag: Line ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['State_'], tag: State, strategy: PickStrategy.HighScore, dataType: DataType.String)])], pipelines: [], target: <datalogue.models.datastore.JdbcDatastoreDef object at 0x000002C5C444EA58>)\n"
     ]
    }
   ],
   "source": [
    "# Define classify transformation\n",
    "from datalogue.models.transformations.classify import Classifier, MLMethod\n",
    "tx_definition = Definition(    # (List[Transformation], pipelines: List['Definition'], target_datastore )\n",
    "            [\n",
    "                Classify(Classifier([MLMethod('b05710cc-62cb-4e59-b337-6fc49fd88433')])),\n",
    "                std_schema\n",
    "            ], # List of transformations\n",
    "        [], # pipelines list\n",
    "            my_output_store, # target_datastore\n",
    "        )\n",
    "\n",
    "print(type(tx_definition))\n",
    "print(tx_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'datalogue.models.stream.Stream'>\n",
      "Stream(type: <datalogue.models.datastore.HttpDatastoreDef object at 0x000002C5C5CBBE10>, pipelines: [Pipeline(type: [Classify(classifier: Classifier(default_class: None classification_methods: \n",
      "[MLMethod(\n",
      " model_id: b05710cc-62cb-4e59-b337-6fc49fd88433, threshold: None\n",
      ")]), fields_to_target: None, add_class_fields: False, add_score_fields: False), Structure(structure: [ClassNodeDescription(path: ['Machine ID_'], tag: Machine ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Part ID_'], tag: Part ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Output Qty_'], tag: Output Qty, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Timestamp_'], tag: Timestamp, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Machine Status_'], tag: Machine Status, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Rejects_'], tag: Rejects, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['City_'], tag: City, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Line ID_'], tag: Line ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['State_'], tag: State, strategy: PickStrategy.HighScore, dataType: DataType.String)])], pipelines: [], target: <datalogue.models.datastore.JdbcDatastoreDef object at 0x000002C5C444EA58>)], env: None)\n"
     ]
    }
   ],
   "source": [
    "# Define n stream(s), where n is number of datastore connections created from S3 bucket scan\n",
    "n = len(current_stores)\n",
    "i = 1\n",
    "\n",
    "list_of_streams = []\n",
    "for i in range(n):\n",
    "    stream = Stream(current_stores[i], [tx_definition])\n",
    "    i += 1\n",
    "    list_of_streams.append(stream)\n",
    "\n",
    "print(type(list_of_streams))\n",
    "print(type(list_of_streams[0]))    \n",
    "print(list_of_streams[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datalogue.models.datastore.Datastore'>\n",
      "Datastore(id: cef0fea6-29fa-4a3d-b819-c263053add37, name: 'demo-mfg/00_data_machine.csv', alias: None, credential_id: None, definition: <datalogue.models.datastore.HttpDatastoreDef object at 0x000002C5C5CBBE10>, samples: None, schema_paths: [], schema_labels: [], schema_nodes: None)\n",
      "\n",
      "\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(type(current_stores[0]))\n",
    "print(current_stores[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(len(list_of_streams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datalogue.models.stream_collection.StreamCollection'>\n",
      "StreamCollection(id: d7b66dd6-34e8-47c6-8dfc-ef0de3ea600a, name: 'demo-MFGPipeline', streams: [StreamMetadata(id: 6ceabe02-2811-477a-8012-1ba8b43937e8, is_ready: False, stream: Stream(type: <datalogue.models.datastore.HttpDatastoreDef object at 0x000002C5C503FC18>, pipelines: [Pipeline(type: [Classify(classifier: Classifier(default_class: None classification_methods: \n",
      "[MLMethod(\n",
      " model_id: b05710cc-62cb-4e59-b337-6fc49fd88433, threshold: None\n",
      ")]), fields_to_target: None, add_class_fields: False, add_score_fields: False), Structure(structure: [ClassNodeDescription(path: ['Machine ID_'], tag: Machine ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Part ID_'], tag: Part ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Output Qty_'], tag: Output Qty, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Timestamp_'], tag: Timestamp, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Machine Status_'], tag: Machine Status, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Rejects_'], tag: Rejects, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['City_'], tag: City, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Line ID_'], tag: Line ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['State_'], tag: State, strategy: PickStrategy.HighScore, dataType: DataType.String)])], pipelines: [], target: <datalogue.models.datastore.JdbcDatastoreDef object at 0x000002C5C503FCC0>)], env: None)), StreamMetadata(id: 73f19bc9-c4a4-4993-a4ed-c8868a516171, is_ready: False, stream: Stream(type: <datalogue.models.datastore.HttpDatastoreDef object at 0x000002C5C53884E0>, pipelines: [Pipeline(type: [Classify(classifier: Classifier(default_class: None classification_methods: \n",
      "[MLMethod(\n",
      " model_id: b05710cc-62cb-4e59-b337-6fc49fd88433, threshold: None\n",
      ")]), fields_to_target: None, add_class_fields: False, add_score_fields: False), Structure(structure: [ClassNodeDescription(path: ['Machine ID_'], tag: Machine ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Part ID_'], tag: Part ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Output Qty_'], tag: Output Qty, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Timestamp_'], tag: Timestamp, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Machine Status_'], tag: Machine Status, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Rejects_'], tag: Rejects, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['City_'], tag: City, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Line ID_'], tag: Line ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['State_'], tag: State, strategy: PickStrategy.HighScore, dataType: DataType.String)])], pipelines: [], target: <datalogue.models.datastore.JdbcDatastoreDef object at 0x000002C5C5388C18>)], env: None)), StreamMetadata(id: 6670100e-0a14-41c6-b943-e7203e249939, is_ready: False, stream: Stream(type: <datalogue.models.datastore.HttpDatastoreDef object at 0x000002C5C4815B38>, pipelines: [Pipeline(type: [Classify(classifier: Classifier(default_class: None classification_methods: \n",
      "[MLMethod(\n",
      " model_id: b05710cc-62cb-4e59-b337-6fc49fd88433, threshold: None\n",
      ")]), fields_to_target: None, add_class_fields: False, add_score_fields: False), Structure(structure: [ClassNodeDescription(path: ['Machine ID_'], tag: Machine ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Part ID_'], tag: Part ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Output Qty_'], tag: Output Qty, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Timestamp_'], tag: Timestamp, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Machine Status_'], tag: Machine Status, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Rejects_'], tag: Rejects, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['City_'], tag: City, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Line ID_'], tag: Line ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['State_'], tag: State, strategy: PickStrategy.HighScore, dataType: DataType.String)])], pipelines: [], target: <datalogue.models.datastore.JdbcDatastoreDef object at 0x000002C5C4815710>)], env: None)), StreamMetadata(id: 4d6b88cf-d0fe-4e6d-a9bb-c9a6cd7bbbe5, is_ready: False, stream: Stream(type: <datalogue.models.datastore.HttpDatastoreDef object at 0x000002C5C5B6C208>, pipelines: [Pipeline(type: [Classify(classifier: Classifier(default_class: None classification_methods: \n",
      "[MLMethod(\n",
      " model_id: b05710cc-62cb-4e59-b337-6fc49fd88433, threshold: None\n",
      ")]), fields_to_target: None, add_class_fields: False, add_score_fields: False), Structure(structure: [ClassNodeDescription(path: ['Machine ID_'], tag: Machine ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Part ID_'], tag: Part ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Output Qty_'], tag: Output Qty, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Timestamp_'], tag: Timestamp, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Machine Status_'], tag: Machine Status, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Rejects_'], tag: Rejects, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['City_'], tag: City, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Line ID_'], tag: Line ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['State_'], tag: State, strategy: PickStrategy.HighScore, dataType: DataType.String)])], pipelines: [], target: <datalogue.models.datastore.JdbcDatastoreDef object at 0x000002C5C5B6C438>)], env: None)), StreamMetadata(id: 7533cac9-3921-4d4e-addf-e28004a12550, is_ready: True, stream: Stream(type: <datalogue.models.datastore.HttpDatastoreDef object at 0x000002C5C5B6C9E8>, pipelines: [Pipeline(type: [Classify(classifier: Classifier(default_class: None classification_methods: \n",
      "[MLMethod(\n",
      " model_id: b05710cc-62cb-4e59-b337-6fc49fd88433, threshold: None\n",
      ")]), fields_to_target: None, add_class_fields: False, add_score_fields: False), Structure(structure: [ClassNodeDescription(path: ['Machine ID_'], tag: Machine ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Part ID_'], tag: Part ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Output Qty_'], tag: Output Qty, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Timestamp_'], tag: Timestamp, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Machine Status_'], tag: Machine Status, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Rejects_'], tag: Rejects, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['City_'], tag: City, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['Line ID_'], tag: Line ID, strategy: PickStrategy.HighScore, dataType: DataType.String), ClassNodeDescription(path: ['State_'], tag: State, strategy: PickStrategy.HighScore, dataType: DataType.String)])], pipelines: [], target: <datalogue.models.datastore.JdbcDatastoreDef object at 0x000002C5C5B6C390>)], env: None))])\n"
     ]
    }
   ],
   "source": [
    "# Put the streams in a collection\n",
    "\n",
    "stream_collection = dtl.stream_collection.create(\n",
    "    list_of_streams,\n",
    "    'demo-MFGPipeline'\n",
    ")\n",
    "\n",
    "print(type(stream_collection))\n",
    "print(stream_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Job(id: UUID('3cd5362d-f8f4-4eaf-85f7-6f1badd2427c'), stream_id: UUID('7533cac9-3921-4d4e-addf-e28004a12550'), stream_collection_id: UUID('d7b66dd6-34e8-47c6-8dfc-ef0de3ea600a'), status: Scheduled, run_at: datetime.datetime(2019, 11, 27, 14, 51, tzinfo=tzutc()), created_by: UUID('5b333964-8fab-4ab0-9052-25f69fcb8689'), remaining_time_millis: 9223372036854775807, percent_progress: 0, errors: None, ended_at: None,\n",
       " Job(id: UUID('157d2dac-ba70-48e0-9ebf-70cfd879e2c7'), stream_id: UUID('4d6b88cf-d0fe-4e6d-a9bb-c9a6cd7bbbe5'), stream_collection_id: UUID('d7b66dd6-34e8-47c6-8dfc-ef0de3ea600a'), status: Scheduled, run_at: datetime.datetime(2019, 11, 27, 14, 51, tzinfo=tzutc()), created_by: UUID('5b333964-8fab-4ab0-9052-25f69fcb8689'), remaining_time_millis: 9223372036854775807, percent_progress: 0, errors: None, ended_at: None,\n",
       " Job(id: UUID('7a4aa347-f09e-4378-8927-b6fad8bc7384'), stream_id: UUID('6670100e-0a14-41c6-b943-e7203e249939'), stream_collection_id: UUID('d7b66dd6-34e8-47c6-8dfc-ef0de3ea600a'), status: Scheduled, run_at: datetime.datetime(2019, 11, 27, 14, 51, tzinfo=tzutc()), created_by: UUID('5b333964-8fab-4ab0-9052-25f69fcb8689'), remaining_time_millis: 9223372036854775807, percent_progress: 0, errors: None, ended_at: None,\n",
       " Job(id: UUID('741ae157-b86a-4ced-b7fa-c2c1309a827c'), stream_id: UUID('73f19bc9-c4a4-4993-a4ed-c8868a516171'), stream_collection_id: UUID('d7b66dd6-34e8-47c6-8dfc-ef0de3ea600a'), status: Scheduled, run_at: datetime.datetime(2019, 11, 27, 14, 51, tzinfo=tzutc()), created_by: UUID('5b333964-8fab-4ab0-9052-25f69fcb8689'), remaining_time_millis: 9223372036854775807, percent_progress: 0, errors: None, ended_at: None,\n",
       " Job(id: UUID('4247f875-4cfe-4c4f-89c6-1401f124e3cd'), stream_id: UUID('6ceabe02-2811-477a-8012-1ba8b43937e8'), stream_collection_id: UUID('d7b66dd6-34e8-47c6-8dfc-ef0de3ea600a'), status: Scheduled, run_at: datetime.datetime(2019, 11, 27, 14, 51, tzinfo=tzutc()), created_by: UUID('5b333964-8fab-4ab0-9052-25f69fcb8689'), remaining_time_millis: 9223372036854775807, percent_progress: 0, errors: None, ended_at: None]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Collection\n",
    "\n",
    "dtl.stream_collection.run(stream_collection.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
